# Unveiling the Attribute Misbinding Threat in Identity-Preserving Models
<font size=4><b> Table of Contents </b></font>

- [Unveiling the Attribute Misbinding Threat in Identity-Preserving Models](#unveiling-the-attribute-misbinding-threat-in-identity-preserving-models)
  - [Framework Overview](#framework-overview)
  - [Attack Demonstration](#attack-demonstration)
  - [Identity-Preserving Models](#identity-preserving-models)
  - [Text Filter](#text-filter)
  - [Safety Evaluation](#safety-evaluation)
  - [Quick Start](#quick-start)
    - [Installation](#installation)
    - [Sensitive Term Expansion](#sensitive-term-expansion)
    - [Attribute Misbinding Attack](#attribute-misbinding-attack)
    - [Attribute Binding Safety Score](#attribute-binding-safety-score)
    - [TEST](#test)



## Framework Overview

<div align="center">
  <img src="./img/frame.jpg" alt="Framework Diagram" width="100%" style="border-radius:8px;box-shadow:0 2px 8px #888;">
</div>


The proposed framework for generating **Misbinding Prompt** evaluation set and evaluating the safety of identity-preserving models.  
The framework consists of four stages:
1. **Sensitive Term Expansion**  
   *Methodically broaden the vocabulary of sensitive terms.*
2. **Attribute Misbinding Attack**  
   *Programmatically create prompts via predefined strategies.*
3. **Diffusion Generation**  
   *Use prompts and identity reference images for synthesis.*
4. **Attribute Binding Safety Score Calculation**  
   *An MLLM assesses the output to calculate the final score.*

---

## Attack Demonstration

<div align="center">
  <img src="./img/show.jpg" alt="Attack Demo" width="100%" style="border-radius:8px;box-shadow:0 2px 8px #888;">
</div>

Demonstration of the proposed Attribute Misbinding Attack against five leading identity-preserving models.  
*To avoid infringing upon the portrait rights of real individuals, all reference face images used in this demonstration are portraits generated by StyleGAN2.*




##  Identity-Preserving Models
The Identity-Preserving Models tested in the paper are as follows:

|  Model            | File name                               | Paper or technical report                                                                                                                                                              |
|------------------|-----------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| UniPortrait  | [UniPortrait_gen.py](./image_generate/UniPortrait_gen.py)  | [UniPortrait: A Unified Framework for Identity-Preserving Single- and Multi-Human Image Personalization](https://arxiv.org/abs/2408.05939) [ICCV2025] |
|  InfiniteYou | [InfiniteYou_gen.py](./image_generate/InfiniteYou_gen.py)  | [InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity](https://arxiv.org/abs/2503.16418) [ICCV 2025 Highlight]|
| PuLID  | [PuLID_gen](image_generate\PuLID_gen.py)  | [PuLID: Pure and Lightning ID Customization via Contrastive Alignment](https://arxiv.org/abs/2404.16022) [NeurIPS 2024]|
| PhotoMaker  | [PhotoMaker_gen.py](./image_generate/PhotoMaker_gen.py)  | [PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding](https://huggingface.co/papers/2312.04461) [CVPR 2024]|
| FLUX.1 Kontext  | [Flux-kontext_gen.py](./image_generate/Flux-kontext_gen.py)  | [FLUX.1 Kontext [dev] is a 12 billion parameter rectified flow transformer capable of editing images based on text instructions.](https://arxiv.org/abs/2506.15742) |


## Text Filter
The Text Filter used in the paper is as follows:
|  Method            |        File name           | GitHub/Hugging Face Pages                                  |
|------------------|-----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| NSFW-TC  | [NSFW_TC.py](./Text_fliter/NSFW_TC.py)  | [Fine-tuned DistilRoBERTa-base for NSFW Classification.](https://huggingface.co/michellejieli/NSFW_text_classifier?not-for-all-audiences=true)  |
| Latent Guard   | [LatenGuard_fliter.py](./Text_fliter/LatenGuard_fliter.py)  | [Democratic AI Safety: No one can define safety for all - Latent Guard helps you define yours.](https://github.com/rt219/LatentGuard)  |
| Detoxify| [detoxify_fliter.py](./Text_fliter/detoxify_fliter.py)  | [Toxic Comment Classification with âš¡ Pytorch Lightning and ðŸ¤— Transformers.](https://github.com/unitaryai/detoxify)  |
| LLM Template| [qwen3_textfilen.py](./Text_fliter/qwen3_textfilen.py)  | |



##  Safety Evaluation
The detectors used for Safety Evaluation in the paper are as follows:
|  Method            |        File name           | GitHub/Hugging Face Pages                                  |
|------------------|-----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Q16 | [q16_evalution.py](./Safety_Evaluation/q16_evalution.py)  | [Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?](https://github.com/ml-research/Q16)  |
| Flux-Fliter | [flux-fliter.py](./Safety_Evaluation/flux-fliter.py)  | [Official inference repo for FLUX.1 models.](https://github.com/black-forest-labs/flux)  |
| MLLM Template| [mllm_imgfliter.py](./Safety_Evaluation/mllm_imgfliter.py)  | |



##  Quick Start

### Installation
You can run the following script to configure the necessary environment:

```
conda create -n AMA python=3.10.4
conda activate AMA
pip install -r requirement.txt
```
### Sensitive Term Expansion

```
python sensitive_term_expansion.py \
    --input "/path/to/your/source_data.xlsx" \
    --output "/path/to/your/custom_output.xlsx" \
    --model_path "HuggingFace_User/Model_Name" \
    --start_row x \
    --end_row y
```
### Attribute Misbinding Attack
```
python Attribute_Misbinding_Attack/attribute_misbinding.py \
    --input "/path/to/another/input.xlsx" \
    --output "/path/to/results_500_1000.xlsx" \
    --model "/path/to/your/local_model" \
    --start x \
    --end y
```

### Attribute Binding Safety Score

```
python Attribute_Misbinding_Attack/abss_calculate.py \
    --input_xlsx "/path/to/another/input.xlsx" \
    --image_dir "/path/to/your/images_directory" \
    --model_path "/path/to/your/local_model" \
    --prompt_col "my_prompts" \
    --image_col "my_images" \
    --start x \
    --end y

```
### TEST

is a new test


























